# 语音助手原理速览

面向 `ai_agents/agents/examples/voice-assistant` 的快速入门，帮助理解为什么有的节点只连一根 `cmd` 线，有的只有 `data` 线。

## 1) 节点职责
- `agora_rtc`：音频/数据的进出通道。
- `streamid_adapter`：给上行音频标记 `metadata.session_id`，便于多流区分。
- `stt`（Deepgram）：把音频转文字，输出 `asr_result`。
- `main_control`（main_python）：编排中心，接收 ASR，调用 LLM，切成句子推给 TTS，并把文字回传 `message_collector`。
- `llm`（openai_llm2_python）：根据 `chat_completion` 命令生成回复。
- `tts`（elevenlabs_tts2_python）：把文字转音频，音频回灌给 `agora_rtc`。
- `message_collector`：收集转写/状态，走 Agora 数据通道给前端展示字幕。
- `weatherapi_tool_python`：作为 LLM 工具（Tool），注册后按需被 LLM 调用。

## 2) 连接类型的逻辑
- `cmd`：像 RPC，请求+响应在一条命令流里传。适用于需要返回值的调用。LLM 只需要一根 `cmd`（`chat_completion`），Tool 也用 `cmd` 注册/调用。
- `data`：单向推送，不期待响应。ASR 结果、TTS 文本输入、字幕消息都用 `data`。
- `audio_frame`：音频帧管道，TTS 输出和 RTC 输入/输出走这里。

## 3) 语音通路（从用户说话到听到回复）
1. 用户音频 → `agora_rtc` → `streamid_adapter`（打上 `session_id`）。
2. `streamid_adapter` → `stt`，输出 `asr_result`（带 metadata.session_id）。
3. `main_control` 收到 `asr_result`：
   - 发送字幕到 `message_collector`（data）。
   - 将最终句子通过 `chat_completion` 命令发给 `llm`。
4. `llm` 在同一 `cmd` 流里返回增量/最终文本，`main_control` 分句后推送 `tts_text_input` 给 `tts`（data）。
5. `tts` 产出音频帧 → `agora_rtc` → 客户端播放。
6. `message_collector` 把字幕通过 Agora 数据通道回给前端。

## 4) 为什么有的节点只有一根线
- LLM：`chat_completion` 命令式接口，结果也在命令流里返回，所以只需要 `cmd` 线。
- Weather Tool：主要是向 `main_control` 注册工具（`tool_register` cmd），真正被调用时也是命令式往返，无需独立 `data` 线。
- message_collector：只负责把文字/状态下行给前端，所以只要一根回传 `data` 线到 `agora_rtc`。

## 5) 快速检查无声问题
- STT 语言：确保与你说话的语言一致（`language: zh` 等）。
- TTS 密钥/网络：日志中若有 401/429/超时，需要有效 key 和可达网络。
- 流 ID：`agora_rtc.stream_id`、`remote_stream_id` 及客户端订阅的流要一致，`streamid_adapter` 会把 `session_id` 透传给 TTS。
- 路由：确认 `tts_text_input` data 线已连到 `tts`，`tts` 的音频帧已回连 `agora_rtc`。

## 6) 进一步查看代码
- 编排逻辑：`ten_packages/extension/main_python/extension.py`、`agent/llm_exec.py`
- LLM：`ten_packages/extension/openai_llm2_python/extension.py`
- Weather Tool：`ten_packages/extension/weatherapi_tool_python/extension.py`
- TTS：`ten_packages/extension/elevenlabs_tts2_python/extension.py`

## 7) 另一套 TTS（抖音/火山 bytedance_tts_duplex）怎么工作的？
把它想成「会说话的水龙头」，打开前要先接好管道、打通水厂：

- 配置拆箱：`config.py` 把 `app_id/token/speaker` 等从 `params` 拿出来，补齐 `audio_params.sample_rate/format`，缺必填就直接报错，避免开局就漏水。
- 出厂登记：`addon.py` 把扩展注册成 `bytedance_tts_duplex`，TEN 知道叫谁来干活。
- 主脑：`extension.py`
  - `on_init` 读配置，建一个 `BytedanceV3Client`，并启动 `_loop` 去吃事件队列。
  - 收到 `tts_text_input`（在 TEN 图里 data 线连过来的文本）后，`request_tts` 会把 request_id/metadata 记好，按需重置/新建连接，把文本丢给客户端。
  - 音频回来时，`_loop` 收到事件就发 `tts_audio_data`，并在开始/结束时发时序指标（TTFB、总时长），有需要还能把 PCM dump 到文件。
  - 如果收到 `tts_flush`，就取消当前会话、发 end 事件，保证「立刻闭嘴」。
- 运输队：`BytedanceV3Client`/`BytedanceV3Synthesizer`（在 `bytedance_tts.py`）
  - Synthesizer 管一条 WebSocket 连接：自动建连、自动重连，内部两个协程，一个专门发（文本、开始/结束 session），一个专门收（音频/事件）。
  - 首包音频回来时算 TTFB，放进事件队列给上层；后续音频就一块块推上去。
  - `finish_session`/`finish_connection` 会按序发控制包，确保服务端优雅收尾；`cancel` 会清空队列、标记关闭，用于 flush。
  - Client 则负责「换水龙头」：若 cancel/reset，就把旧的 synthesizer 丢进清理队列，开一个新的，避免旧连接残留导致混音。

一句话：`bytedance_tts_duplex` 负责「接管文本，建 WebSocket，源源不断吐出音频」，`main_control` 只要把 `tts_text_input` 连过去，`agora_rtc` 把音频帧收回来，客户端就能听到抖音/火山的声音。
